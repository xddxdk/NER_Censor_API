{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ae9de9",
   "metadata": {},
   "source": [
    "### **Подготовка данных**\n",
    "***\n",
    "**Загрузка и обработка текста**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92759e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd557d",
   "metadata": {},
   "source": [
    "Для подготовки обучающих данных, были загружены датасеты с негативными комментариями:\n",
    "\n",
    "Russian Language Toxic Comments Dataset (файл rltd.csv) - основной датасет для работы с токсичными комментариями на русском языке. Опубликован на Kaggle в 2019 году и содержит 14,412 комментариев, из которых 4,826 помечены как токсичные, а 9,586 — как нетоксичные\n",
    "\n",
    "MCA Workshop - Toxic Comments Dataset - датасет токсичных комментариев, собранный во время первого воркшопа Математического центра в Академгородке. Содержит размеченные комментарии из социальной сети ВКонтакте\n",
    "\n",
    "Объеденим датасеты и возьмем исключительно тексты комментариев, для последующей разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee51037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comment', 'toxic'], dtype='object') Index(['Unnamed: 0', 'source', 'text', 'message', 'sex', 'decent', 'moral',\n",
      "       'person'],\n",
      "      dtype='object')\n",
      "<bound method DataFrame.info of                                                    text\n",
      "0                  Верблюдов-то за что? Дебилы, бл...\\n\n",
      "1     Хохлы, это отдушина затюканого россиянина, мол...\n",
      "2                             Собаке - собачья смерть\\n\n",
      "3     Страницу обнови, дебил. Это тоже не оскорблени...\n",
      "4     тебя не убедил 6-страничный пдф в том, что Скр...\n",
      "...                                                 ...\n",
      "3799                 [id584786137|Μάρκ], в этом с(м)ысл\n",
      "3800  [id510533373|Sasha], «правильные», а судьи кто...\n",
      "3801  [id88928627|Владислав], правильные это греческ...\n",
      "3802  [id510533373|Sasha], почему не римский стандар...\n",
      "3803  [id88928627|Владислав], поддерживаю этнос варв...\n",
      "\n",
      "[18216 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('C:/Users/kpodd/OneDrive/Desktop/ml/NER/data/rltcd.csv')\n",
    "df2 = pd.read_csv('C:/Users/kpodd/OneDrive/Desktop/ml/NER/data/mcaw.csv')\n",
    "print(df1.columns, df2.columns)\n",
    "df1, df2 = df1['comment'], df2['message']\n",
    "df = pd.DataFrame(pd.concat([df1, df2], axis=0), columns=['text'])\n",
    "print(df.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599db8a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7ff4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...\n",
       "2                          Собаке - собачья смерть\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Удаление пустых строк и пробелов\n",
    "df = df[df[\"text\"].str.strip() != \"\"]\n",
    "df = df.dropna()\n",
    "display(df.head(3))\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64763e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим файл, содержащий перечень нецензурных слов русского языка (2300 слов)\n",
    "# Файл был взят с - https://gitverse.ru/gen/russian_ban_words\n",
    "with open('C:/Users/kpodd/OneDrive/Desktop/ml/NER/data/ru_curse_words.txt', 'r', encoding='utf-8') as f:\n",
    "    bad_words = set([line.strip().lower() for line in f if line.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffbc806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>верблюдов то за что дебилы бл</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>хохлы это отдушина затюканого россиянина мол в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>собаке собачья смерть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>страницу обнови дебил это тоже не оскорбление ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>тебя не убедил страничный пдф в том что скрипа...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n   \n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...   \n",
       "2                          Собаке - собачья смерть\\n   \n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...   \n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...   \n",
       "\n",
       "                                          clean_text  \n",
       "0                      верблюдов то за что дебилы бл  \n",
       "1  хохлы это отдушина затюканого россиянина мол в...  \n",
       "2                              собаке собачья смерть  \n",
       "3  страницу обнови дебил это тоже не оскорбление ...  \n",
       "4  тебя не убедил страничный пдф в том что скрипа...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                                    text  \\\n",
      "0                  Верблюдов-то за что? Дебилы, бл...\\n   \n",
      "1     Хохлы, это отдушина затюканого россиянина, мол...   \n",
      "2                             Собаке - собачья смерть\\n   \n",
      "3     Страницу обнови, дебил. Это тоже не оскорблени...   \n",
      "4     тебя не убедил 6-страничный пдф в том, что Скр...   \n",
      "...                                                 ...   \n",
      "3799                 [id584786137|Μάρκ], в этом с(м)ысл   \n",
      "3800  [id510533373|Sasha], «правильные», а судьи кто...   \n",
      "3801  [id88928627|Владислав], правильные это греческ...   \n",
      "3802  [id510533373|Sasha], почему не римский стандар...   \n",
      "3803  [id88928627|Владислав], поддерживаю этнос варв...   \n",
      "\n",
      "                                             clean_text  \n",
      "0                         верблюдов то за что дебилы бл  \n",
      "1     хохлы это отдушина затюканого россиянина мол в...  \n",
      "2                                 собаке собачья смерть  \n",
      "3     страницу обнови дебил это тоже не оскорбление ...  \n",
      "4     тебя не убедил страничный пдф в том что скрипа...  \n",
      "...                                                 ...  \n",
      "3799                                       в этом смысл  \n",
      "3800  правильные а судьи кто и почему у балтидов неп...  \n",
      "3801  владислав правильные это греческий стандарт кр...  \n",
      "3802  почему не римский стандарт красоты и каким обр...  \n",
      "3803  владислав поддерживаю этнос варвара есть ещё э...  \n",
      "\n",
      "[18198 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^а-яА-ЯёЁ\\s\\-.,!?;:]', '', text) # Удаление нерусских слов\n",
    "    text = str(text).lower() # Lowercase\n",
    "    text = re.sub(r'http\\S+', '', text) # HTML\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[\\U00010000-\\U0001FFFF]', '', text) # Emoji\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text) # Пунктуация\n",
    "    text = re.sub(r'\\d+', '', text) # Числа\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Extra spaces\n",
    "    return text\n",
    "    \n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "display(df.head(5))\n",
    "print(df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b79c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b119c6",
   "metadata": {},
   "source": [
    "***\n",
    "Токенизация и BIO-разметка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30fb77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa91ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация и разметка\n",
    "def tokenize_and_label(text, bad_words, truncation=True, padding = \"max_length\", max_length = 256):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    labels = []\n",
    "\n",
    "    current_word_tokens = []\n",
    "    current_word = ''\n",
    "    output_tokens = []\n",
    "    output_labels = []\n",
    "\n",
    "    for tok in tokens:\n",
    "        if tok.startswith(\"##\"): # учет сплитов с ##\n",
    "            sub_tok = tok[2:]\n",
    "            current_word += sub_tok\n",
    "            current_word_tokens.append(tok)\n",
    "        else:\n",
    "            if current_word_tokens:\n",
    "                word_lower = current_word.lower()\n",
    "                label_seq = ['B-PRF'] + ['I-PRF'] * (len(current_word_tokens) - 1) if word_lower in bad_words else ['O'] * len(current_word_tokens)\n",
    "                output_tokens.extend(current_word_tokens)\n",
    "                output_labels.extend(label_seq)\n",
    "            # начинаем новое слово\n",
    "            current_word = tok\n",
    "            current_word_tokens = [tok]\n",
    "    # последнее слово\n",
    "    if current_word_tokens:\n",
    "        word_lower = current_word.lower()\n",
    "        label_seq = ['B-PRF'] + ['I-PRF'] * (len(current_word_tokens) - 1) if word_lower in bad_words else ['O'] * len(current_word_tokens)\n",
    "        output_tokens.extend(current_word_tokens)\n",
    "        output_labels.extend(label_seq)\n",
    "\n",
    "    return output_tokens, output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48322cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sequences = []\n",
    "label_sequences = []\n",
    "df = pd.read_csv('C:/Users/kpodd/OneDrive/Desktop/ml/NER/data/data_clean.csv')\n",
    "texts = df['clean_text'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f55b7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2bea3363374fd590a20c9dc01c7db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for text in tqdm(texts):\n",
    "    tokens, labels = tokenize_and_label(text, bad_words)\n",
    "    token_sequences.append(tokens)\n",
    "    label_sequences.append(labels)\n",
    "\n",
    "assert all(len(t) == len(l) for t, l in zip(token_sequences, label_sequences)) # ошибка в длине токенов и меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc67be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame({\n",
    "    'tokens': token_sequences,\n",
    "    'labels': label_sequences\n",
    "})\n",
    "label_df.to_csv('C:/Users/kpodd/OneDrive/Desktop/ml/NER/data/data_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f186fc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[верблю, ##дов, то, за, что, дебил, ##ы, бл]</td>\n",
       "      <td>[O, O, O, O, O, B-PRF, I-PRF, B-PRF]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tokens  \\\n",
       "0  [верблю, ##дов, то, за, что, дебил, ##ы, бл]   \n",
       "\n",
       "                                 labels  \n",
       "0  [O, O, O, O, O, B-PRF, I-PRF, B-PRF]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Уже на первом примере можно увидеть, как работает разметка\n",
    "display(label_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a424d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 539780, 'B-PRF': 3647, 'I-PRF': 3350})\n"
     ]
    }
   ],
   "source": [
    "# Статистика разметки\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "print(Counter(chain.from_iterable(label_df['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3f4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_pickle(\"C:/Users/kpodd/OneDrive/Desktop/ml/NER/data/data_label.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
